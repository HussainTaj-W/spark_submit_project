[PATHS]

#
# All paths assume the present working directory to 
# the same as the shell/console that launched ssh.sh
#

# The file that holds the requirements(package names) one per line.
Requirements File = requirements.txt

# The directory where the downloaded files are kept.
# Everything in this file is deleted when the ssp.sh runs again.
Libraries Directory = ./.spark-submit-project/lib

# The directory where your code resides.
# All files in this directory are send in spark-submit.
Source Code Directory = src

# The directory where the archive of source code is kept.
Distribution Directory = ./.spark-submit-project/dist

# A file that holds the complete paths of files that need to be passed to 
# spark-submit in the --py-files argument.
Include Code File = include/include_code.txt

# A directory whose top level files and directories(archived) are sent to spark-submit as --py-files.
Include Code Directory = include/code

# A file that holds the complete paths of files that need to be passed to 
# spark-submit in the --files argument.
# if [OPTIONS] section's 'Use Archive Argument = True' then zip files are passed to '--archives' argument.
Include Assets File = include/include_assets.txt

# A directory whose top level files and directories(archived) are sent to spark-submit as --files.
# Archives are zip and if [OPTIONS] section's 'Use Archive Argument = True' 
# then zip files are passed to '--archives' argument.
Include Assets Directory = include/assets



[LOGGING]

# Level is an integer, higher the number, the less number of logs you'll see.
# Visit https://docs.python.org/3/library/logging.html#logging-levels for more details.

Level = 20



[OPTIONS]

# Whether or not you want to use --archives argument of spark-submit.
# Asset includes that are .zip are sent as --archives if this option is true,
# Otherwise, the files are sent as --files argument.
Use Archive Argument = True